{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "877dad16-2ca4-4acd-acc0-064c3f5a8cd0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "source": [
    "<!-- TOC -->\n",
    "# Table of Contents\n",
    "\n",
    "- [\ud83d\udd27 Environment Setup](#\ud83d\udd27-environment-setup)\n",
    "- [\ud83d\udcd0 Batch Processing Configuration](#\ud83d\udcd0-batch-processing-configuration)\n",
    "- [\ud83d\udcbe Initialize Checkpoint System](#\ud83d\udcbe-initialize-checkpoint-system)\n",
    "- [\ud83d\udcc2 Scan Video Directories](#\ud83d\udcc2-scan-video-directories)\n",
    "- [\ud83c\udfaf Find Target Videos](#\ud83c\udfaf-find-target-videos)\n",
    "- [\ud83d\udcbe Save Video Manifest](#\ud83d\udcbe-save-video-manifest)\n",
    "- [\ud83c\udfac Preview Extraction Configuration](#\ud83c\udfac-preview-extraction-configuration)\n",
    "- [\ud83c\udfa5 Extract Preview Frames](#\ud83c\udfa5-extract-preview-frames)\n",
    "- [\ud83d\udcca Display Frame Previews](#\ud83d\udcca-display-frame-previews)\n",
    "- [\ud83d\udcc8 Quality Analysis & Recommendations](#\ud83d\udcc8-quality-analysis-&-recommendations)\n",
    "- [\ud83d\udcda Quality Metrics Reference](#\ud83d\udcda-quality-metrics-reference)\n",
    "  - [Brightness (Luminance)](#brightness-(luminance))\n",
    "  - [Blur Score (Laplacian Variance)](#blur-score-(laplacian-variance))\n",
    "  - [Quartile-Based Outlier Detection](#quartile-based-outlier-detection)\n",
    "  - [Color Space Conversion (BGR to RGB)](#color-space-conversion-(bgr-to-rgb))\n",
    "- [\ud83d\udcbe Export Selection for Individual Processing](#\ud83d\udcbe-export-selection-for-individual-processing)\n",
    "- [\ud83d\udccb Batch Processing Summary](#\ud83d\udccb-batch-processing-summary)\n",
    "\n",
    "<!-- /TOC -->\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "af0da59d-2595-41e5-8394-f466cd1de53a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "source": [
    "## \ud83d\udd27 Environment Setup\n",
    "\n",
    "This cell establishes the batch preprocessing environment by:\n",
    "\n",
    "1. **Importing Required Libraries**\n",
    "  - OpenCV (cv2) for video processing and frame extraction\n",
    "  - NumPy for array operations\n",
    "  - Pandas for organizing metadata and results\n",
    "  - Pathlib for cross-platform file path handling\n",
    "  - JSON for checkpoint persistence\n",
    "  - Datetime for timestamp parsing and filtering\n",
    "  - Logging for process tracking\n",
    "\n",
    "2. **Setting System Paths**\n",
    "  - Adding mlops_ops modules to Python path\n",
    "  - Verifying access to preprocessing utilities\n",
    "\n",
    "3. **Initializing Checkpoint System**\n",
    "  - Loading any previous processing state\n",
    "  - Setting up progress tracking variables\n",
    "  - Establishing failure recovery mechanism\n",
    "\n",
    "**Note**: Run this cell first to ensure all dependencies are available before proceeding with batch processing."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bea106-187f-47dd-a300-44aec39f2005",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# Cell 2 - Environment Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add mlops modules to path\n",
    "sys.path.insert(0, '../lib')\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Check for OpenCV\n",
    "try:\n",
    "    import cv2\n",
    "    print(f\"\u2713 OpenCV version: {cv2.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"\u26a0\ufe0f OpenCV not installed. Install with: pip install opencv-python\")\n",
    "    print(\"   Continuing without video processing capabilities...\")\n",
    "    cv2 = None\n",
    "\n",
    "print(f\"\u2713 Python version: {sys.version.split()[0]}\")\n",
    "print(f\"\u2713 Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70e2904-fcff-4d19-919b-cc63c029d0a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "source": [
    "## \ud83d\udcd0 Batch Processing Configuration\n",
    "\n",
    "Define the core parameters for daily batch preprocessing:\n",
    "\n",
    "- **Target Time**: Extract frames from videos closest to 12:00 PM EST\n",
    "- **Date Filter**: Process only videos from yesterday (full calendar day)\n",
    "- **Frame Count**: Number of frames to extract per video\n",
    "- **Input Path**: Base directory containing camera subdirectories\n",
    "- **Output Path**: Where to save extracted frames\n",
    "- **File Pattern**: Expected video filename format (CAMERA_YYYYMMDD_HHMMSS.mp4)\n",
    "\n",
    "This configuration serves as the single source of truth for the batch processing workflow."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d90cc9-659c-4536-9062-19f701c38f6b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# Cell 3 - Batch Processing Configuration\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "   # Time targeting\n",
    "   'TARGET_TIME': '120000',  # 12:00:00 in 24-hour format\n",
    "   'TARGET_HOUR': 12,\n",
    "   \n",
    "   # Date filtering - yesterday only\n",
    "   'PROCESS_DATE': (datetime.now() - timedelta(days=1)).strftime('%Y%m%d'),\n",
    "   \n",
    "   # Frame extraction\n",
    "   'FRAMES_PER_VIDEO': 10,\n",
    "   \n",
    "   # Paths\n",
    "   'INPUT_DIR': Path.home() / 'traffic-recordings',\n",
    "   'OUTPUT_DIR': Path('batch_processed_frames'),\n",
    "   \n",
    "   # File pattern\n",
    "   'VIDEO_PATTERN': '*_{date}_*.mp4',  # Will be formatted with PROCESS_DATE\n",
    "   'FILENAME_FORMAT': '{camera}_{date}_{time}.mp4'  # Expected format\n",
    "}\n",
    "\n",
    "# Display configuration\n",
    "print(\"Batch Processing Configuration:\")\n",
    "print(f\"  Target Date: {CONFIG['PROCESS_DATE']}\")\n",
    "print(f\"  Target Time: {CONFIG['TARGET_TIME']} (12:00:00)\")\n",
    "print(f\"  Frames per video: {CONFIG['FRAMES_PER_VIDEO']}\")\n",
    "print(f\"  Input: {CONFIG['INPUT_DIR']}\")\n",
    "print(f\"  Output: {CONFIG['OUTPUT_DIR']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ad1c64-a59c-4c60-b74c-788e94b80f74",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "source": [
    "## \ud83d\udcbe Initialize Checkpoint System\n",
    "\n",
    "Create checkpoint functionality to track processing progress and enable recovery from interruptions. This system saves state after each video completes, allowing the workflow to resume from the last successful video if stopped."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a30d389-c60b-44de-a4ed-d77dd92bf8d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# Cell 4 - Initialize Checkpoint System\n",
    "CHECKPOINT_FILE = \"batch_preprocessing_checkpoint.json\"\n",
    "start_time = datetime.now()\n",
    "\n",
    "def load_checkpoint():\n",
    "   \"\"\"Load previous progress if exists\"\"\"\n",
    "   if Path(CHECKPOINT_FILE).exists():\n",
    "       with open(CHECKPOINT_FILE, 'r') as f:\n",
    "           checkpoint = json.load(f)\n",
    "           print(f\"\u2713 Loaded checkpoint: {len(checkpoint['processed'])} videos already processed\")\n",
    "           return checkpoint\n",
    "   return {\n",
    "       \"processed\": [], \n",
    "       \"failed\": [], \n",
    "       \"last_completed\": None,\n",
    "       \"process_date\": CONFIG['PROCESS_DATE'],\n",
    "       \"start_time\": start_time.isoformat()\n",
    "   }\n",
    "\n",
    "def save_checkpoint(checkpoint):\n",
    "   \"\"\"Save current progress\"\"\"\n",
    "   checkpoint['last_updated'] = datetime.now().isoformat()\n",
    "   with open(CHECKPOINT_FILE, 'w') as f:\n",
    "       json.dump(checkpoint, f, indent=2)\n",
    "\n",
    "# Initialize checkpoint\n",
    "checkpoint = load_checkpoint()\n",
    "\n",
    "# Verify checkpoint is for current date\n",
    "if checkpoint.get('process_date') != CONFIG['PROCESS_DATE']:\n",
    "   print(f\"\u26a0\ufe0f  Checkpoint is from {checkpoint.get('process_date')}, starting fresh for {CONFIG['PROCESS_DATE']}\")\n",
    "   checkpoint = {\n",
    "       \"processed\": [], \n",
    "       \"failed\": [], \n",
    "       \"last_completed\": None,\n",
    "       \"process_date\": CONFIG['PROCESS_DATE'],\n",
    "       \"start_time\": start_time.isoformat()\n",
    "   }\n",
    "\n",
    "print(f\"\u2713 Checkpoint system ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891b639d-f96f-4fc1-8eeb-791af329973a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "source": [
    "## \ud83d\udcc2 Scan Video Directories\n",
    "\n",
    "Enumerate all camera subdirectories and count available videos from yesterday's date. This provides an overview of the data available for processing and identifies any cameras that may be missing recordings."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e55d2-0fc3-46b5-b00e-e5c4792c1ab8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# Cell 5 - Scan Video Directories (Updated)\n",
    "camera_dirs = sorted([d for d in CONFIG['INPUT_DIR'].iterdir() if d.is_dir() and d.name.startswith('ATL-')])\n",
    "print(f\"Found {len(camera_dirs)} camera directories\\n\")\n",
    "\n",
    "# Count videos per camera for yesterday\n",
    "video_counts = {}\n",
    "date_folder = CONFIG['PROCESS_DATE'][:4] + '-' + CONFIG['PROCESS_DATE'][4:6] + '-' + CONFIG['PROCESS_DATE'][6:8]  # Convert to YYYY-MM-DD\n",
    "pattern = CONFIG['VIDEO_PATTERN'].format(date=CONFIG['PROCESS_DATE'])\n",
    "\n",
    "for cam_dir in camera_dirs:\n",
    "    date_dir = cam_dir / date_folder\n",
    "    if date_dir.exists():\n",
    "        videos = list(date_dir.glob(pattern))\n",
    "        video_counts[cam_dir.name] = len(videos)\n",
    "        \n",
    "        if len(videos) == 0:\n",
    "            print(f\"\u26a0\ufe0f  {cam_dir.name}: No videos in {date_folder}\")\n",
    "        else:\n",
    "            print(f\"\u2713 {cam_dir.name}: {len(videos)} videos\")\n",
    "    else:\n",
    "        video_counts[cam_dir.name] = 0\n",
    "        print(f\"\u26a0\ufe0f  {cam_dir.name}: No {date_folder} directory\")\n",
    "\n",
    "total_videos = sum(video_counts.values())\n",
    "print(f\"\\nTotal videos available: {total_videos}\")\n",
    "print(f\"Cameras with recordings: {sum(1 for v in video_counts.values() if v > 0)}/{len(camera_dirs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f988f5f6-c80b-4dba-9d01-903d07e6ed6c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "source": [
    "## \ud83c\udfaf Find Target Videos\n",
    "\n",
    "Parse timestamps from video filenames and identify the video closest to 12:00:00 (noon) for each camera. This creates the final list of videos to process."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e74452-cdee-4780-8c78-a092478a1661",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# Cell 6 - Find Target Videos\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_timestamp(filename):\n",
    "   \"\"\"Extract timestamp from filename and calculate minutes from midnight\"\"\"\n",
    "   # Format: ATL-XXXX_YYYYMMDD_HHMMSS.mp4\n",
    "   parts = filename.stem.split('_')\n",
    "   if len(parts) >= 3:\n",
    "       time_str = parts[2]\n",
    "       hours = int(time_str[:2])\n",
    "       minutes = int(time_str[2:4])\n",
    "       seconds = int(time_str[4:6])\n",
    "       return hours * 60 + minutes  # Minutes from midnight\n",
    "   return None\n",
    "\n",
    "def find_closest_to_noon(video_list):\n",
    "   \"\"\"Find video closest to 12:00:00\"\"\"\n",
    "   target_minutes = CONFIG['TARGET_HOUR'] * 60  # 720 minutes (12:00)\n",
    "   \n",
    "   closest_video = None\n",
    "   min_diff = float('inf')\n",
    "   \n",
    "   for video in video_list:\n",
    "       minutes = parse_timestamp(video)\n",
    "       if minutes is not None:\n",
    "           diff = abs(minutes - target_minutes)\n",
    "           if diff < min_diff:\n",
    "               min_diff = diff\n",
    "               closest_video = video\n",
    "   \n",
    "   return closest_video, min_diff\n",
    "\n",
    "# Find target videos for each camera\n",
    "target_videos = []\n",
    "date_folder = CONFIG['PROCESS_DATE'][:4] + '-' + CONFIG['PROCESS_DATE'][4:6] + '-' + CONFIG['PROCESS_DATE'][6:8]\n",
    "\n",
    "for cam_dir in camera_dirs:\n",
    "   date_dir = cam_dir / date_folder\n",
    "   if date_dir.exists():\n",
    "       videos = list(date_dir.glob(f\"{cam_dir.name}_*.mp4\"))\n",
    "       if videos:\n",
    "           closest, diff_minutes = find_closest_to_noon(videos)\n",
    "           if closest:\n",
    "               target_videos.append({\n",
    "                   'camera': cam_dir.name,\n",
    "                   'video_path': closest,\n",
    "                   'time_diff_minutes': diff_minutes\n",
    "               })\n",
    "               time_str = closest.stem.split('_')[2]\n",
    "               print(f\"{cam_dir.name}: {time_str[:2]}:{time_str[2:4]}:{time_str[4:6]} ({diff_minutes} min from noon)\")\n",
    "\n",
    "print(f\"\\nTotal videos to process: {len(target_videos)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c68ad76-a257-4995-b5a5-68a08dbd5ce3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "source": [
    "## \ud83d\udcbe Save Video Manifest\n",
    "\n",
    "Create a manifest file containing all selected videos (one per camera closest to noon) with metadata. This manifest serves as the input for individual video preprocessing and review."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d81f18d-9d9c-4fb7-8601-a159c621d497",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# Cell 7 - Save Video Manifest\n",
    "manifest_data = {\n",
    "   'processing_date': CONFIG['PROCESS_DATE'],\n",
    "   'target_time': CONFIG['TARGET_TIME'],\n",
    "   'created_at': datetime.now().isoformat(),\n",
    "   'total_cameras': len(camera_dirs),\n",
    "   'videos_found': len(target_videos),\n",
    "   'videos': []\n",
    "}\n",
    "\n",
    "for video_info in target_videos:\n",
    "   video_path = video_info['video_path']\n",
    "   time_str = video_path.stem.split('_')[2]\n",
    "   \n",
    "   manifest_data['videos'].append({\n",
    "       'camera': video_info['camera'],\n",
    "       'filename': video_path.name,\n",
    "       'full_path': str(video_path),\n",
    "       'recording_time': f\"{time_str[:2]}:{time_str[2:4]}:{time_str[4:6]}\",\n",
    "       'time_diff_minutes': video_info['time_diff_minutes'],\n",
    "       'file_size_mb': round(video_path.stat().st_size / (1024*1024), 2)\n",
    "   })\n",
    "\n",
    "# Save manifest\n",
    "manifest_file = Path(f\"batch_manifest_{CONFIG['PROCESS_DATE']}.json\")\n",
    "with open(manifest_file, 'w') as f:\n",
    "   json.dump(manifest_data, f, indent=2)\n",
    "\n",
    "# Also save as CSV for easy viewing\n",
    "df_manifest = pd.DataFrame(manifest_data['videos'])\n",
    "csv_file = Path(f\"batch_manifest_{CONFIG['PROCESS_DATE']}.csv\")\n",
    "df_manifest.to_csv(csv_file, index=False)\n",
    "\n",
    "print(f\"\u2713 Saved manifest: {manifest_file}\")\n",
    "print(f\"\u2713 Saved CSV: {csv_file}\")\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Videos selected: {len(target_videos)}\")\n",
    "print(f\"  Total size: {df_manifest['file_size_mb'].sum():.1f} MB\")\n",
    "print(f\"  Average time from noon: {df_manifest['time_diff_minutes'].mean():.1f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0ad1c2-4797-4196-a3b2-dcbbc116333f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "source": [
    "## \ud83c\udfac Preview Extraction Configuration\n",
    "\n",
    "Define parameters for extracting sample frames from each video. These settings control how many frames to extract and from which portion of the video to generate quality previews."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7713a87-f1d5-4acd-a7da-c0fc530d0cac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# Cell 8 - Preview Extraction Configuration\n",
    "PREVIEW_CONFIG = {\n",
    "   'frames_per_video': 5,          # Number of frames to extract per video\n",
    "   'extraction_duration': 60,      # Extract from first 60 seconds only\n",
    "   'preview_dir': Path('batch_preview_frames'),\n",
    "   'max_videos_to_preview': 10     # Limit for initial testing\n",
    "}\n",
    "\n",
    "# Create output directory\n",
    "PREVIEW_CONFIG['preview_dir'].mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Preview Configuration:\")\n",
    "print(f\"  Frames per video: {PREVIEW_CONFIG['frames_per_video']}\")\n",
    "print(f\"  Duration to sample: {PREVIEW_CONFIG['extraction_duration']}s\")\n",
    "print(f\"  Output directory: {PREVIEW_CONFIG['preview_dir']}\")\n",
    "print(f\"  Max videos: {PREVIEW_CONFIG['max_videos_to_preview']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0a5a94-0850-4f15-a4ab-aaf014eb0405",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "source": [
    "## \ud83c\udfa5 Extract Preview Frames\n",
    "\n",
    "Process selected videos to extract sample frames with quality metrics. This generates visual previews and calculates brightness/blur scores to help identify videos requiring individual review."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929423e5-ab21-4b63-800b-06c456bdbe52",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# Install OpenCV\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"opencv-python\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188bb1a4-c47b-4374-bcce-bd139579643b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# Cell 9 - Extract Preview Frames\n",
    "import cv2\n",
    "\n",
    "def extract_preview_frames(video_path, output_dir, num_frames=5, duration_seconds=60):\n",
    "   \"\"\"Extract evenly spaced frames from video for preview\"\"\"\n",
    "   cap = cv2.VideoCapture(str(video_path))\n",
    "   if not cap.isOpened():\n",
    "       return None\n",
    "   \n",
    "   fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "   total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "   duration_frames = min(int(fps * duration_seconds), total_frames)\n",
    "   \n",
    "   # Calculate frame indices\n",
    "   indices = np.linspace(0, duration_frames-1, num_frames, dtype=int)\n",
    "   \n",
    "   frames_data = []\n",
    "   for idx in indices:\n",
    "       cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "       ret, frame = cap.read()\n",
    "       if ret:\n",
    "           # Calculate metrics\n",
    "           gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "           brightness = np.mean(gray)\n",
    "           blur_score = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "           \n",
    "           # Save frame\n",
    "           frame_filename = f\"frame_{idx:04d}.jpg\"\n",
    "           frame_path = output_dir / frame_filename\n",
    "           cv2.imwrite(str(frame_path), frame)\n",
    "           \n",
    "           frames_data.append({\n",
    "               'index': idx,\n",
    "               'brightness': brightness,\n",
    "               'blur_score': blur_score,\n",
    "               'path': frame_path\n",
    "           })\n",
    "   \n",
    "   cap.release()\n",
    "   return frames_data\n",
    "\n",
    "# Process videos\n",
    "print(\"Extracting preview frames...\")\n",
    "preview_results = []\n",
    "\n",
    "for i, video_info in enumerate(target_videos[:PREVIEW_CONFIG['max_videos_to_preview']]):\n",
    "   camera = video_info['camera']\n",
    "   video_path = video_info['video_path']\n",
    "   \n",
    "   # Create output directory\n",
    "   output_dir = PREVIEW_CONFIG['preview_dir'] / f\"{camera}_{CONFIG['PROCESS_DATE']}\"\n",
    "   output_dir.mkdir(exist_ok=True)\n",
    "   \n",
    "   # Extract frames\n",
    "   frames_data = extract_preview_frames(\n",
    "       video_path, \n",
    "       output_dir,\n",
    "       PREVIEW_CONFIG['frames_per_video'],\n",
    "       PREVIEW_CONFIG['extraction_duration']\n",
    "   )\n",
    "   \n",
    "   if frames_data:\n",
    "       avg_brightness = np.mean([f['brightness'] for f in frames_data])\n",
    "       avg_blur = np.mean([f['blur_score'] for f in frames_data])\n",
    "       \n",
    "       preview_results.append({\n",
    "           'camera': camera,\n",
    "           'video_path': video_path,\n",
    "           'frames_extracted': len(frames_data),\n",
    "           'avg_brightness': avg_brightness,\n",
    "           'avg_blur_score': avg_blur,\n",
    "           'frames_data': frames_data\n",
    "       })\n",
    "       \n",
    "       print(f\"\u2713 {camera}: {len(frames_data)} frames, brightness={avg_brightness:.1f}, blur={avg_blur:.1f}\")\n",
    "   else:\n",
    "       print(f\"\u2717 {camera}: Failed to extract frames\")\n",
    "\n",
    "print(f\"\\nCompleted preview extraction for {len(preview_results)} videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100dcc1f-2abe-430a-800b-389245db8999",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "source": [
    "## \ud83d\udcca Display Frame Previews\n",
    "\n",
    "Generate visual grid showing extracted frames from each camera with quality metrics. This provides a quick overview to identify which videos need closer inspection."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cacd3c6-083b-4fb2-a65d-9b74cead433d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# Cell 10 - Display Frame Previews\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(len(preview_results), PREVIEW_CONFIG['frames_per_video'], \n",
    "                       figsize=(PREVIEW_CONFIG['frames_per_video'] * 3, len(preview_results) * 2.5))\n",
    "\n",
    "if len(preview_results) == 1:\n",
    "   axes = axes.reshape(1, -1)\n",
    "\n",
    "for cam_idx, result in enumerate(preview_results):\n",
    "   camera = result['camera']\n",
    "   \n",
    "   # Display each frame\n",
    "   for frame_idx, frame_data in enumerate(result['frames_data']):\n",
    "       ax = axes[cam_idx, frame_idx]\n",
    "       \n",
    "       # Read and display frame\n",
    "       img = cv2.imread(str(frame_data['path']))\n",
    "       img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "       ax.imshow(img_rgb)\n",
    "       ax.set_title(f\"Frame {frame_data['index']}\\nB:{frame_data['brightness']:.0f} S:{frame_data['blur_score']:.0f}\", \n",
    "                   fontsize=8)\n",
    "       ax.axis('off')\n",
    "   \n",
    "   # Add camera label\n",
    "   axes[cam_idx, 0].text(-0.1, 0.5, f\"{camera}\\nAvg B:{result['avg_brightness']:.0f}\\nAvg S:{result['avg_blur_score']:.0f}\", \n",
    "                         transform=axes[cam_idx, 0].transAxes,\n",
    "                         ha='right', va='center', fontsize=10, weight='bold')\n",
    "\n",
    "plt.suptitle(f'Batch Preview - {CONFIG[\"PROCESS_DATE\"]} @ 12:00', fontsize=14, y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "df_preview = pd.DataFrame([{\n",
    "   'camera': r['camera'],\n",
    "   'brightness': r['avg_brightness'],\n",
    "   'blur_score': r['avg_blur_score']\n",
    "} for r in preview_results])\n",
    "\n",
    "print(f\"\\nQuality Summary:\")\n",
    "print(f\"  Brightness range: {df_preview['brightness'].min():.1f} - {df_preview['brightness'].max():.1f}\")\n",
    "print(f\"  Blur score range: {df_preview['blur_score'].min():.1f} - {df_preview['blur_score'].max():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32c7631-dab2-45d9-983a-8010c9d20061",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "source": [
    "## \ud83d\udcc8 Quality Analysis & Recommendations\n",
    "\n",
    "Analyze the extracted frames to identify patterns and generate recommendations for which videos may need individual review based on quality metrics."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d34d2-e99d-4fca-ba3b-8522da383ef3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# Cell 11 - Quality Analysis & Recommendations\n",
    "# Analyze quality metrics\n",
    "df_quality = pd.DataFrame([{\n",
    "   'camera': r['camera'],\n",
    "   'brightness': r['avg_brightness'],\n",
    "   'blur_score': r['avg_blur_score']\n",
    "} for r in preview_results])\n",
    "\n",
    "# Define quality thresholds\n",
    "brightness_low = df_quality['brightness'].quantile(0.25)\n",
    "brightness_high = df_quality['brightness'].quantile(0.75)\n",
    "blur_low = df_quality['blur_score'].quantile(0.25)\n",
    "blur_high = df_quality['blur_score'].quantile(0.75)\n",
    "\n",
    "# Identify videos needing review\n",
    "needs_review = []\n",
    "\n",
    "for r in preview_results:\n",
    "   issues = []\n",
    "   if r['avg_brightness'] < brightness_low:\n",
    "       issues.append('low brightness')\n",
    "   elif r['avg_brightness'] > brightness_high:\n",
    "       issues.append('high brightness')\n",
    "   \n",
    "   if r['avg_blur_score'] < blur_low:\n",
    "       issues.append('high blur')\n",
    "   \n",
    "   if issues:\n",
    "       needs_review.append({\n",
    "           'camera': r['camera'],\n",
    "           'issues': ', '.join(issues),\n",
    "           'brightness': r['avg_brightness'],\n",
    "           'blur_score': r['avg_blur_score']\n",
    "       })\n",
    "\n",
    "# Display recommendations\n",
    "print(\"Quality Analysis Results:\")\n",
    "print(f\"  Brightness quartiles: Q1={brightness_low:.1f}, Q3={brightness_high:.1f}\")\n",
    "print(f\"  Blur score quartiles: Q1={blur_low:.1f}, Q3={blur_high:.1f}\")\n",
    "\n",
    "if needs_review:\n",
    "   print(f\"\\nVideos needing review ({len(needs_review)}):\")\n",
    "   for video in needs_review:\n",
    "       print(f\"  {video['camera']}: {video['issues']}\")\n",
    "else:\n",
    "   print(\"\\nAll videos within normal quality ranges\")\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_quality['brightness'], df_quality['blur_score'], s=100)\n",
    "\n",
    "for idx, row in df_quality.iterrows():\n",
    "   plt.annotate(row['camera'], (row['brightness'], row['blur_score']), \n",
    "               xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "plt.axvline(brightness_low, color='red', linestyle='--', alpha=0.5, label='Brightness Q1')\n",
    "plt.axvline(brightness_high, color='red', linestyle='--', alpha=0.5, label='Brightness Q3')\n",
    "plt.axhline(blur_low, color='blue', linestyle='--', alpha=0.5, label='Blur Q1')\n",
    "\n",
    "plt.xlabel('Brightness')\n",
    "plt.ylabel('Blur Score (higher = sharper)')\n",
    "plt.title(f'Video Quality Distribution - {CONFIG[\"PROCESS_DATE\"]}')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a2b9a7-0f20-4868-a1e6-a0e45fa54b67",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "source": [
    "## \ud83d\udcda Quality Metrics Reference\n",
    "\n",
    "### Brightness (Luminance)\n",
    "Average pixel intensity across the image, measured on a 0-255 scale for 8-bit images.\n",
    "- **Calculation**: Mean of grayscale pixel values\n",
    "- **Reference**: [OpenCV Image Processing](https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html)\n",
    "- **MLOps Context**: [Google Cloud - Image Quality Assessment](https://cloud.google.com/vision/docs/detecting-properties)\n",
    "\n",
    "### Blur Score (Laplacian Variance)\n",
    "Measures image sharpness by computing variance of the Laplacian operator output.\n",
    "- **Higher values** = Sharper image (more edge detail)\n",
    "- **Lower values** = Blurrier image (less edge detail)\n",
    "- **Technical Details**: [Laplacian Operator - SciPy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.laplace.html)\n",
    "- **Research Paper**: [Diatom autofocusing in brightfield microscopy](https://www.researchgate.net/publication/234073097_Diatom_autofocusing_in_brightfield_microscopy_A_comparative_study)\n",
    "\n",
    "### Quartile-Based Outlier Detection\n",
    "Statistical method using Q1 (25th percentile) and Q3 (75th percentile) to identify anomalies.\n",
    "- **Pandas Documentation**: [DataFrame.quantile](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html)\n",
    "- **Statistical Background**: [NIST - Quartiles](https://www.itl.nist.gov/div898/handbook/prc/section2/prc252.htm)\n",
    "\n",
    "### Color Space Conversion (BGR to RGB)\n",
    "OpenCV uses BGR format by default; conversion needed for matplotlib display.\n",
    "- **OpenCV Reference**: [Color Space Conversions](https://docs.opencv.org/4.x/d8/d01/group__imgproc__color__conversions.html)\n",
    "- **Why BGR?**: [Historical reasons from Windows API](https://learnopencv.com/why-does-opencv-use-bgr-color-format/)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8a2e4376-91bf-4fe1-870b-0e7d7666736b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "source": [
    "## \ud83d\udcbe Export Selection for Individual Processing\n",
    "\n",
    "Create a queue file listing which cameras to process individually. This file will be read by the individual preprocessing notebook to focus on specific videos that need detailed review.\n",
    "\n",
    "Selection options:\n",
    "- **Automatic**: Based on quality outliers identified above\n",
    "- **Manual**: Specify camera IDs directly\n",
    "- **All**: Process all previewed cameras"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e6d719-f36d-40a7-ba9e-205084646833",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# Cell 12 - Export Selection for Individual Processing\n",
    "# Allow manual selection or use quality-based recommendations\n",
    "selected_cameras = []\n",
    "\n",
    "# Option 1: Auto-select based on quality issues\n",
    "for video in needs_review:\n",
    "   selected_cameras.append(video['camera'])\n",
    "\n",
    "# Option 2: Manual override (uncomment and modify as needed)\n",
    "# selected_cameras = ['ATL-0006', 'ATL-0027', 'ATL-0069']  \n",
    "\n",
    "# Option 3: Select all\n",
    "# selected_cameras = [r['camera'] for r in preview_results]\n",
    "\n",
    "# Save selection\n",
    "selection_data = {\n",
    "   'batch_date': CONFIG['PROCESS_DATE'],\n",
    "   'selected_cameras': selected_cameras,\n",
    "   'selection_criteria': 'quality_based',  # or 'manual' or 'all'\n",
    "   'created_at': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "selection_file = Path(f\"individual_processing_queue_{CONFIG['PROCESS_DATE']}.json\")\n",
    "with open(selection_file, 'w') as f:\n",
    "   json.dump(selection_data, f, indent=2)\n",
    "\n",
    "print(f\"\u2713 Saved {len(selected_cameras)} cameras for individual processing\")\n",
    "print(f\"  File: {selection_file}\")\n",
    "if selected_cameras:\n",
    "   print(f\"  Cameras: {', '.join(selected_cameras)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1462158-d664-48d8-b6e6-4b4f93c7d693",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "source": [
    "## \ud83d\udccb Batch Processing Summary\n",
    "\n",
    "Generate final summary report showing what was accomplished and next steps for the workflow."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa7989b-6bb3-4a06-ac68-372af1ff36d7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# Cell 13 - Batch Processing Summary\n",
    "print(\"=\"*60)\n",
    "print(f\"BATCH PROCESSING SUMMARY - {CONFIG['PROCESS_DATE']}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Processing Statistics:\")\n",
    "print(f\"  Total cameras: {len(camera_dirs)}\")\n",
    "print(f\"  Videos found: {len(target_videos)}\")\n",
    "print(f\"  Videos previewed: {len(preview_results)}\")\n",
    "print(f\"  Frames extracted: {len(preview_results) * PREVIEW_CONFIG['frames_per_video']}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcc8 Quality Overview:\")\n",
    "print(f\"  Avg brightness: {df_quality['brightness'].mean():.1f} (range: {df_quality['brightness'].min():.1f}-{df_quality['brightness'].max():.1f})\")\n",
    "print(f\"  Avg blur score: {df_quality['blur_score'].mean():.0f} (range: {df_quality['blur_score'].min():.0f}-{df_quality['blur_score'].max():.0f})\")\n",
    "print(f\"  Videos flagged for review: {len(needs_review)}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcc1 Output Files:\")\n",
    "print(f\"  Manifest: batch_manifest_{CONFIG['PROCESS_DATE']}.json\")\n",
    "print(f\"  Preview frames: {PREVIEW_CONFIG['preview_dir']}/\")\n",
    "print(f\"  Individual queue: {selection_file.name}\")\n",
    "\n",
    "print(f\"\\n\u2705 Next Steps:\")\n",
    "print(f\"  1. Review visual previews above\")\n",
    "print(f\"  2. Run individual preprocessing notebook\")\n",
    "print(f\"  3. Load queue file: {selection_file.name}\")\n",
    "\n",
    "print(f\"\\nCompleted at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c0a341-0173-4137-8fb4-a7cc53f95df7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}