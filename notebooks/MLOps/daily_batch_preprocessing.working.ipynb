{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b9d10c5-195d-41d2-b74c-12b3e06f642c",
   "metadata": {},
   "source": [
    "# üìì Notebook Manager\n",
    "\n",
    "This cell initializes the widgets required for managing your research notebook. Please run the cell below to enable functionality for:\n",
    "- Exporting cells tagged with `export` into a `clean` notebook\n",
    "- Generating a dynamic Table of Contents (TOC)\n",
    "- Exporting the notebook to GitHub-compatible Markdown\n",
    "\n",
    "‚û°Ô∏è **Be sure to execute the next cell before continuing with any editing or exporting.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95312728-5bf6-40b4-854e-fbc5ff4b14e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47849d84f03242b29b103ef0c9721110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Button(button_style='primary', description='Generate TOC', icon='list', style=Bu‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 1 - Workflow Tools\n",
    "import sys\n",
    "sys.path.insert(0, '../../lib')\n",
    "\n",
    "from notebook_tools import TOCWidget, ExportWidget\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "# Create widget instances\n",
    "toc = TOCWidget()\n",
    "export = ExportWidget()\n",
    "\n",
    "# Create horizontal layout\n",
    "left_side = widgets.VBox([toc.button, export.button, toc.status])\n",
    "right_side = widgets.VBox([toc.output, export.output])\n",
    "\n",
    "# Display side by side\n",
    "display(widgets.HBox([left_side, right_side]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc58eef-463e-465b-9b53-acdd3bc398dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# üìë Table of Contents (Auto-Generated)\n",
    "\n",
    "This section will automatically generate a table of contents for your research notebook once you run the **Generate TOC** function. The table of contents will help you navigate through your data collection, analysis, and findings as your citizen science project develops.\n",
    "\n",
    "‚û°Ô∏è **Do not edit this cell manually. It will be overwritten automatically.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877dad16-2ca4-4acd-acc0-064c3f5a8cd0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "export"
    ]
   },
   "source": [
    "<!-- TOC -->\n",
    "# Table of Contents\n",
    "\n",
    "\n",
    "<!-- /TOC -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0da59d-2595-41e5-8394-f466cd1de53a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## üîß Environment Setup\n",
    "\n",
    "This cell establishes the batch preprocessing environment by:\n",
    "\n",
    "1. **Importing Required Libraries**\n",
    "  - OpenCV (cv2) for video processing and frame extraction\n",
    "  - NumPy for array operations\n",
    "  - Pandas for organizing metadata and results\n",
    "  - Pathlib for cross-platform file path handling\n",
    "  - JSON for checkpoint persistence\n",
    "  - Datetime for timestamp parsing and filtering\n",
    "  - Logging for process tracking\n",
    "\n",
    "2. **Setting System Paths**\n",
    "  - Adding mlops_ops modules to Python path\n",
    "  - Verifying access to preprocessing utilities\n",
    "\n",
    "3. **Initializing Checkpoint System**\n",
    "  - Loading any previous processing state\n",
    "  - Setting up progress tracking variables\n",
    "  - Establishing failure recovery mechanism\n",
    "\n",
    "**Note**: Run this cell first to ensure all dependencies are available before proceeding with batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4bea106-187f-47dd-a300-44aec39f2005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è OpenCV not installed. Install with: pip install opencv-python\n",
      "   Continuing without video processing capabilities...\n",
      "‚úì Python version: 3.12.9\n",
      "‚úì Working directory: /home/trauco/v3-traffic-vision/notebooks/MLOps\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 - Environment Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add mlops modules to path\n",
    "sys.path.insert(0, '../lib')\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Check for OpenCV\n",
    "try:\n",
    "    import cv2\n",
    "    print(f\"‚úì OpenCV version: {cv2.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è OpenCV not installed. Install with: pip install opencv-python\")\n",
    "    print(\"   Continuing without video processing capabilities...\")\n",
    "    cv2 = None\n",
    "\n",
    "print(f\"‚úì Python version: {sys.version.split()[0]}\")\n",
    "print(f\"‚úì Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70e2904-fcff-4d19-919b-cc63c029d0a8",
   "metadata": {},
   "source": [
    "## üìê Batch Processing Configuration\n",
    "\n",
    "Define the core parameters for daily batch preprocessing:\n",
    "\n",
    "- **Target Time**: Extract frames from videos closest to 12:00 PM EST\n",
    "- **Date Filter**: Process only videos from yesterday (full calendar day)\n",
    "- **Frame Count**: Number of frames to extract per video\n",
    "- **Input Path**: Base directory containing camera subdirectories\n",
    "- **Output Path**: Where to save extracted frames\n",
    "- **File Pattern**: Expected video filename format (CAMERA_YYYYMMDD_HHMMSS.mp4)\n",
    "\n",
    "This configuration serves as the single source of truth for the batch processing workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7d90cc9-659c-4536-9062-19f701c38f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Processing Configuration:\n",
      "  Target Date: 20250620\n",
      "  Target Time: 120000 (12:00:00)\n",
      "  Frames per video: 10\n",
      "  Input: /home/trauco/traffic-recordings\n",
      "  Output: batch_processed_frames\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 - Batch Processing Configuration\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "   # Time targeting\n",
    "   'TARGET_TIME': '120000',  # 12:00:00 in 24-hour format\n",
    "   'TARGET_HOUR': 12,\n",
    "   \n",
    "   # Date filtering - yesterday only\n",
    "   'PROCESS_DATE': (datetime.now() - timedelta(days=1)).strftime('%Y%m%d'),\n",
    "   \n",
    "   # Frame extraction\n",
    "   'FRAMES_PER_VIDEO': 10,\n",
    "   \n",
    "   # Paths\n",
    "   'INPUT_DIR': Path.home() / 'traffic-recordings',\n",
    "   'OUTPUT_DIR': Path('batch_processed_frames'),\n",
    "   \n",
    "   # File pattern\n",
    "   'VIDEO_PATTERN': '*_{date}_*.mp4',  # Will be formatted with PROCESS_DATE\n",
    "   'FILENAME_FORMAT': '{camera}_{date}_{time}.mp4'  # Expected format\n",
    "}\n",
    "\n",
    "# Display configuration\n",
    "print(\"Batch Processing Configuration:\")\n",
    "print(f\"  Target Date: {CONFIG['PROCESS_DATE']}\")\n",
    "print(f\"  Target Time: {CONFIG['TARGET_TIME']} (12:00:00)\")\n",
    "print(f\"  Frames per video: {CONFIG['FRAMES_PER_VIDEO']}\")\n",
    "print(f\"  Input: {CONFIG['INPUT_DIR']}\")\n",
    "print(f\"  Output: {CONFIG['OUTPUT_DIR']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ad1c64-a59c-4c60-b74c-788e94b80f74",
   "metadata": {},
   "source": [
    "## üíæ Initialize Checkpoint System\n",
    "\n",
    "Create checkpoint functionality to track processing progress and enable recovery from interruptions. This system saves state after each video completes, allowing the workflow to resume from the last successful video if stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a30d389-c60b-44de-a4ed-d77dd92bf8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Checkpoint system ready\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 - Initialize Checkpoint System\n",
    "CHECKPOINT_FILE = \"batch_preprocessing_checkpoint.json\"\n",
    "start_time = datetime.now()\n",
    "\n",
    "def load_checkpoint():\n",
    "   \"\"\"Load previous progress if exists\"\"\"\n",
    "   if Path(CHECKPOINT_FILE).exists():\n",
    "       with open(CHECKPOINT_FILE, 'r') as f:\n",
    "           checkpoint = json.load(f)\n",
    "           print(f\"‚úì Loaded checkpoint: {len(checkpoint['processed'])} videos already processed\")\n",
    "           return checkpoint\n",
    "   return {\n",
    "       \"processed\": [], \n",
    "       \"failed\": [], \n",
    "       \"last_completed\": None,\n",
    "       \"process_date\": CONFIG['PROCESS_DATE'],\n",
    "       \"start_time\": start_time.isoformat()\n",
    "   }\n",
    "\n",
    "def save_checkpoint(checkpoint):\n",
    "   \"\"\"Save current progress\"\"\"\n",
    "   checkpoint['last_updated'] = datetime.now().isoformat()\n",
    "   with open(CHECKPOINT_FILE, 'w') as f:\n",
    "       json.dump(checkpoint, f, indent=2)\n",
    "\n",
    "# Initialize checkpoint\n",
    "checkpoint = load_checkpoint()\n",
    "\n",
    "# Verify checkpoint is for current date\n",
    "if checkpoint.get('process_date') != CONFIG['PROCESS_DATE']:\n",
    "   print(f\"‚ö†Ô∏è  Checkpoint is from {checkpoint.get('process_date')}, starting fresh for {CONFIG['PROCESS_DATE']}\")\n",
    "   checkpoint = {\n",
    "       \"processed\": [], \n",
    "       \"failed\": [], \n",
    "       \"last_completed\": None,\n",
    "       \"process_date\": CONFIG['PROCESS_DATE'],\n",
    "       \"start_time\": start_time.isoformat()\n",
    "   }\n",
    "\n",
    "print(f\"‚úì Checkpoint system ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891b639d-f96f-4fc1-8eeb-791af329973a",
   "metadata": {},
   "source": [
    "## üìÇ Scan Video Directories\n",
    "\n",
    "Enumerate all camera subdirectories and count available videos from yesterday's date. This provides an overview of the data available for processing and identifies any cameras that may be missing recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67b1bff8-c167-460d-a1cf-594f13d10b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31 camera directories\n",
      "\n",
      "‚ö†Ô∏è  ATL-0006: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0027: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0069: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0080: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0150: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0540: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0610: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0612: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0613: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0907: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0917: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0922: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0943: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0946: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0947: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0948: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0952: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0972: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0973: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0980: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0981: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0987: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0992: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0996: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0997: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0998: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-0999: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-1000: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-1001: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-1005: No videos from 20250620\n",
      "‚ö†Ô∏è  ATL-1031: No videos from 20250620\n",
      "\n",
      "Total videos available: 0\n",
      "Cameras with recordings: 0/31\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 - Scan Video Directories\n",
    "camera_dirs = sorted([d for d in CONFIG['INPUT_DIR'].iterdir() if d.is_dir() and d.name.startswith('ATL-')])\n",
    "print(f\"Found {len(camera_dirs)} camera directories\\n\")\n",
    "\n",
    "# Count videos per camera for yesterday\n",
    "video_counts = {}\n",
    "pattern = CONFIG['VIDEO_PATTERN'].format(date=CONFIG['PROCESS_DATE'])\n",
    "\n",
    "for cam_dir in camera_dirs:\n",
    "   videos = list(cam_dir.glob(pattern))\n",
    "   video_counts[cam_dir.name] = len(videos)\n",
    "   \n",
    "   if len(videos) == 0:\n",
    "       print(f\"‚ö†Ô∏è  {cam_dir.name}: No videos from {CONFIG['PROCESS_DATE']}\")\n",
    "   else:\n",
    "       print(f\"‚úì {cam_dir.name}: {len(videos)} videos\")\n",
    "\n",
    "total_videos = sum(video_counts.values())\n",
    "print(f\"\\nTotal videos available: {total_videos}\")\n",
    "print(f\"Cameras with recordings: {sum(1 for v in video_counts.values() if v > 0)}/{len(camera_dirs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1292d59c-e811-494b-b276-76c497e11da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking ATL-0006 for all video files:\n",
      "Total videos: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 5b - Debug: Check actual video files\n",
    "# Check first camera directory for actual file pattern\n",
    "test_cam = camera_dirs[0]\n",
    "print(f\"Checking {test_cam.name} for all video files:\")\n",
    "\n",
    "all_videos = list(test_cam.glob(\"*.mp4\"))\n",
    "print(f\"Total videos: {len(all_videos)}\")\n",
    "\n",
    "if all_videos:\n",
    "    # Show first 5 filenames to see pattern\n",
    "    print(\"\\nSample filenames:\")\n",
    "    for video in all_videos[:5]:\n",
    "        print(f\"  {video.name}\")\n",
    "    \n",
    "    # Check for yesterday's date in any position\n",
    "    yesterday_videos = [v for v in all_videos if CONFIG['PROCESS_DATE'] in v.name]\n",
    "    print(f\"\\nVideos containing {CONFIG['PROCESS_DATE']}: {len(yesterday_videos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e55d2-0fc3-46b5-b00e-e5c4792c1ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
